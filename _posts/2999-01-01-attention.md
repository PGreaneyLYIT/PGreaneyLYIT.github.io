---
title: 'Attention for NLP'
date: 2999-04-22
permalink: /posts/2999/01/attention/
tags:
  - attention
  - nlp
  - deep learning
---

All you need is attention.


$$\begin{pmatrix}0.1\\ 0.8\\ 0.2\end{pmatrix}$$
